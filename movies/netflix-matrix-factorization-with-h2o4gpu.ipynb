{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's install `h2o4gpu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "\r\n",
      "The following additional packages will be installed:\r\n",
      "  libopenblas-base\r\n",
      "The following NEW packages will be installed:\r\n",
      "  libopenblas-base libopenblas-dev pbzip2\r\n",
      "0 upgraded, 3 newly installed, 0 to remove and 46 not upgraded.\r\n",
      "Need to get 7644 kB of archives.\r\n",
      "After this operation, 91.6 MB of additional disk space will be used.\r\n",
      "Get:1 http://deb.debian.org/debian stretch/main amd64 libopenblas-base amd64 0.2.19-3 [3793 kB]\r\n",
      "Get:2 http://deb.debian.org/debian stretch/main amd64 libopenblas-dev amd64 0.2.19-3 [3809 kB]\r\n",
      "Get:3 http://deb.debian.org/debian stretch/main amd64 pbzip2 amd64 1.1.9-1+b1 [41.8 kB]\r\n",
      "Fetched 7644 kB in 0s (40.6 MB/s)\r\n",
      "debconf: delaying package configuration, since apt-utils is not installed\r\n",
      "Selecting previously unselected package libopenblas-base.\r\n",
      "(Reading database ... 37072 files and directories currently installed.)\r\n",
      "Preparing to unpack .../libopenblas-base_0.2.19-3_amd64.deb ...\r\n",
      "Unpacking libopenblas-base (0.2.19-3) ...\r\n",
      "Selecting previously unselected package libopenblas-dev.\r\n",
      "Preparing to unpack .../libopenblas-dev_0.2.19-3_amd64.deb ...\r\n",
      "Unpacking libopenblas-dev (0.2.19-3) ...\r\n",
      "Selecting previously unselected package pbzip2.\r\n",
      "Preparing to unpack .../pbzip2_1.1.9-1+b1_amd64.deb ...\r\n",
      "Unpacking pbzip2 (1.1.9-1+b1) ...\r\n",
      "Setting up pbzip2 (1.1.9-1+b1) ...\r\n",
      "Processing triggers for libc-bin (2.24-11+deb9u3) ...\r\n",
      "Setting up libopenblas-base (0.2.19-3) ...\r\n",
      "update-alternatives: using /usr/lib/openblas-base/libblas.so.3 to provide /usr/lib/libblas.so.3 (libblas.so.3) in auto mode\r\n",
      "update-alternatives: using /usr/lib/openblas-base/liblapack.so.3 to provide /usr/lib/liblapack.so.3 (liblapack.so.3) in auto mode\r\n",
      "Setting up libopenblas-dev (0.2.19-3) ...\r\n",
      "update-alternatives: using /usr/lib/openblas-base/libblas.so to provide /usr/lib/libblas.so (libblas.so) in auto mode\r\n",
      "update-alternatives: using /usr/lib/openblas-base/liblapack.so to provide /usr/lib/liblapack.so (liblapack.so) in auto mode\r\n",
      "Processing triggers for libc-bin (2.24-11+deb9u3) ...\r\n",
      "Collecting tabulate==0.8.2\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/c2/11d6845db5edf1295bc08b2f488cf5937806586afe42936c3f34c097ebdc/tabulate-0.8.2.tar.gz (45kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 2.5MB/s \r\n",
      "\u001b[?25hBuilding wheels for collected packages: tabulate\r\n",
      "  Building wheel for tabulate (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/.cache/pip/wheels/2a/85/33/2f6da85d5f10614cbe5a625eab3b3aebfdf43e7b857f25f829\r\n",
      "Successfully built tabulate\r\n",
      "\u001b[31mtensorpack 0.9.1 has requirement msgpack-numpy>=0.4.4.2, but you'll have msgpack-numpy 0.4.3.2 which is incompatible.\u001b[0m\r\n",
      "Installing collected packages: tabulate\r\n",
      "  Found existing installation: tabulate 0.8.3\r\n",
      "    Uninstalling tabulate-0.8.3:\r\n",
      "      Successfully uninstalled tabulate-0.8.3\r\n",
      "Successfully installed tabulate-0.8.2\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/opt/conda/bin/pip\", line 11, in <module>\r\n",
      "    sys.exit(main())\r\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pip/_internal/__init__.py\", line 78, in main\r\n",
      "    return command.main(cmd_args)\r\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pip/_internal/cli/base_command.py\", line 228, in main\r\n",
      "    timeout=min(5, options.timeout)\r\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pip/_internal/cli/base_command.py\", line 93, in _build_session\r\n",
      "    insecure_hosts=options.trusted_hosts,\r\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pip/_internal/download.py\", line 344, in __init__\r\n",
      "    self.headers[\"User-Agent\"] = user_agent()\r\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pip/_internal/download.py\", line 134, in user_agent\r\n",
      "    setuptools_version = get_installed_version(\"setuptools\")\r\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pip/_internal/utils/misc.py\", line 902, in get_installed_version\r\n",
      "    working_set = pkg_resources.WorkingSet()\r\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 565, in __init__\r\n",
      "    self.add_entry(entry)\r\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 621, in add_entry\r\n",
      "    for dist in find_distributions(entry, True):\r\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 1886, in find_eggs_in_zip\r\n",
      "    if metadata.has_metadata('PKG-INFO'):\r\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 1405, in has_metadata\r\n",
      "    return self.egg_info and self._has(self._fn(self.egg_info, name))\r\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 1760, in _has\r\n",
      "    return zip_path in self.zipinfo or zip_path in self._index()\r\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 1637, in zipinfo\r\n",
      "    return self._zip_manifests.load(self.loader.archive)\r\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 1594, in load\r\n",
      "    mtime = os.stat(path).st_mtime\r\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/opt/conda/lib/python3.6/site-packages/tabulate-0.8.3-py3.6.egg'\r\n",
      "Collecting h2o4gpu\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/8d/fa90e4acebba21cd58f8d6b94289e11422bd996330f3973fca3243613c1f/h2o4gpu-0.3.1-cp36-cp36m-manylinux1_x86_64.whl (356.5MB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 356.5MB 47kB/s \r\n",
      "\u001b[?25hCollecting pytest-forked==0.2 (from h2o4gpu)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/dd/9d/fb75af584b850a902c9ce5ec96ea5c623978113b8a240ab414e1a435df93/pytest_forked-0.2-py2.py3-none-any.whl\r\n",
      "Requirement already satisfied: pylint==1.8.4 in /opt/conda/lib/python3.6/site-packages (from h2o4gpu) (1.8.4)\r\n",
      "Requirement already satisfied: tabulate==0.8.2 in /opt/conda/lib/python3.6/site-packages (from h2o4gpu) (0.8.2)\r\n",
      "Collecting numpy==1.16.1 (from h2o4gpu)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/bf/4981bcbee43934f0adb8f764a1e70ab0ee5a448f6505bd04a87a2fda2a8b/numpy-1.16.1-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 17.3MB 2.8MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: pytz==2018.4 in /opt/conda/lib/python3.6/site-packages (from h2o4gpu) (2018.4)\r\n",
      "Collecting scikit-learn==0.20.2 (from h2o4gpu)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0d/3a/b92670f5c368c20329ecc4c255993fae7934564d485c3ed7ea7b8da7f741/scikit_learn-0.20.2-cp36-cp36m-manylinux1_x86_64.whl (5.4MB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 5.4MB 7.8MB/s \r\n",
      "\u001b[?25hCollecting pandas==0.24.1 (from h2o4gpu)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/de/a0d3defd8f338eaf53ef716e40ef6d6c277c35d50e09b586e170169cdf0d/pandas-0.24.1-cp36-cp36m-manylinux1_x86_64.whl (10.1MB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 10.1MB 5.4MB/s \r\n",
      "\u001b[?25hCollecting python-dateutil==2.7.2 (from h2o4gpu)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/57/19f3a65bcf6d5be570ee8c35a5398496e10a0ddcbc95393b2d17f86aaaf8/python_dateutil-2.7.2-py2.py3-none-any.whl (212kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 215kB 30.8MB/s \r\n",
      "\u001b[?25hCollecting psutil==5.4.5 (from h2o4gpu)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/a2/8ac7dda36eac03950ec2668ab1b466314403031c83a95c5efc81d2acf163/psutil-5.4.5.tar.gz (418kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 419kB 33.0MB/s \r\n",
      "\u001b[?25hCollecting pytest-cov==2.5.1 (from h2o4gpu)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/30/7d/7f6a78ae44a1248ee28cc777586c18b28a1df903470e5d34a6e25712b8aa/pytest_cov-2.5.1-py2.py3-none-any.whl\r\n",
      "Collecting scipy==1.2.1 (from h2o4gpu)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7f/5f/c48860704092933bf1c4c1574a8de1ffd16bf4fde8bab190d747598844b2/scipy-1.2.1-cp36-cp36m-manylinux1_x86_64.whl (24.8MB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 24.8MB 2.1MB/s \r\n",
      "\u001b[?25hCollecting pytest-xdist==1.22.2 (from h2o4gpu)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/30/77/78da3a2ace46a7bee0059d5772472f95f31bf2ba0ce8dbb8e4d8582c323c/pytest_xdist-1.22.2-py2.py3-none-any.whl\r\n",
      "Collecting future==0.16.0 (from h2o4gpu)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/2b/8d082ddfed935f3608cc61140df6dcbf0edea1bc3ab52fb6c29ae3e81e85/future-0.16.0.tar.gz (824kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 829kB 30.3MB/s \r\n",
      "\u001b[?25hCollecting pytest==3.10.1 (from h2o4gpu)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/94/305477fb977546970a3464c21b63c6800df6705384af2978b89acccfb151/pytest-3.10.1-py2.py3-none-any.whl (216kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 225kB 27.4MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: astroid<2.0,>=1.6 in /opt/conda/lib/python3.6/site-packages (from pylint==1.8.4->h2o4gpu) (1.6.3)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from pylint==1.8.4->h2o4gpu) (1.12.0)\r\n",
      "Requirement already satisfied: isort>=4.2.5 in /opt/conda/lib/python3.6/site-packages (from pylint==1.8.4->h2o4gpu) (4.3.4)\r\n",
      "Requirement already satisfied: mccabe in /opt/conda/lib/python3.6/site-packages (from pylint==1.8.4->h2o4gpu) (0.6.1)\r\n",
      "Requirement already satisfied: coverage>=3.7.1 in /opt/conda/lib/python3.6/site-packages (from pytest-cov==2.5.1->h2o4gpu) (4.5.3)\r\n",
      "Collecting execnet>=1.1 (from pytest-xdist==1.22.2->h2o4gpu)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/f9/76/3343e69a2a1602052f587898934e5fea395d22310d39c07955596597227c/execnet-1.5.0-py2.py3-none-any.whl\r\n",
      "Requirement already satisfied: py>=1.5.0 in /opt/conda/lib/python3.6/site-packages (from pytest==3.10.1->h2o4gpu) (1.5.3)\r\n",
      "Collecting pluggy>=0.7 (from pytest==3.10.1->h2o4gpu)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/84/e8/4ddac125b5a0e84ea6ffc93cfccf1e7ee1924e88f53c64e98227f0af2a5f/pluggy-0.9.0-py2.py3-none-any.whl\r\n",
      "Collecting atomicwrites>=1.0 (from pytest==3.10.1->h2o4gpu)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/52/90/6155aa926f43f2b2a22b01be7241be3bfd1ceaf7d0b3267213e8127d41f4/atomicwrites-1.3.0-py2.py3-none-any.whl\r\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.6/site-packages (from pytest==3.10.1->h2o4gpu) (18.1.0)\r\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /opt/conda/lib/python3.6/site-packages (from pytest==3.10.1->h2o4gpu) (4.1.0)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from pytest==3.10.1->h2o4gpu) (39.1.0)\r\n",
      "Requirement already satisfied: lazy_object_proxy in /opt/conda/lib/python3.6/site-packages (from astroid<2.0,>=1.6->pylint==1.8.4->h2o4gpu) (1.3.1)\r\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.6/site-packages (from astroid<2.0,>=1.6->pylint==1.8.4->h2o4gpu) (1.10.11)\r\n",
      "Collecting apipkg>=1.4 (from execnet>=1.1->pytest-xdist==1.22.2->h2o4gpu)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/67/08/4815a09603fc800209431bec5b8bd2acf2f95abdfb558a44a42507fb94da/apipkg-1.5-py2.py3-none-any.whl\r\n",
      "Building wheels for collected packages: psutil, future\r\n",
      "  Building wheel for psutil (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/.cache/pip/wheels/9e/9d/6d/234974c01e6aa3ab6215738bfe74c30704ce28219fee8c40bb\r\n",
      "  Building wheel for future (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/.cache/pip/wheels/bf/c9/a3/c538d90ef17cf7823fa51fc701a7a7a910a80f6a405bf15b1a\r\n",
      "Successfully built psutil future\r\n",
      "\u001b[31mtsfresh 0.11.2 has requirement pandas<=0.23.4,>=0.20.3, but you'll have pandas 0.24.1 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mtensorpack 0.9.1 has requirement msgpack-numpy>=0.4.4.2, but you'll have msgpack-numpy 0.4.3.2 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mmxnet-cu100 1.4.0.post0 has requirement numpy<1.15.0,>=1.8.2, but you'll have numpy 1.16.1 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mlime 0.1.1.33 has requirement matplotlib==2.1.0, but you'll have matplotlib 3.0.3 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mkmodes 0.9 has requirement scikit-learn<0.20.0,>=0.19.0, but you'll have scikit-learn 0.20.2 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mkmeans-smote 0.1.0 has requirement imbalanced-learn<0.4,>=0.3.1, but you'll have imbalanced-learn 0.5.0.dev0 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mkmeans-smote 0.1.0 has requirement numpy<1.15,>=1.13, but you'll have numpy 1.16.1 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mkmeans-smote 0.1.0 has requirement scikit-learn<0.20,>=0.19.0, but you'll have scikit-learn 0.20.2 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mfeaturetools 0.6.1 has requirement psutil>=5.4.8, but you'll have psutil 5.4.5 which is incompatible.\u001b[0m\r\n",
      "Installing collected packages: pluggy, atomicwrites, pytest, pytest-forked, numpy, scipy, scikit-learn, python-dateutil, pandas, psutil, pytest-cov, apipkg, execnet, pytest-xdist, future, h2o4gpu\r\n",
      "  Found existing installation: pluggy 0.6.0\r\n",
      "    Uninstalling pluggy-0.6.0:\r\n",
      "      Successfully uninstalled pluggy-0.6.0\r\n",
      "  Found existing installation: pytest 3.5.1\r\n",
      "    Uninstalling pytest-3.5.1:\r\n",
      "      Successfully uninstalled pytest-3.5.1\r\n",
      "  Found existing installation: numpy 1.16.2\r\n",
      "    Uninstalling numpy-1.16.2:\r\n",
      "      Successfully uninstalled numpy-1.16.2\r\n",
      "  Found existing installation: scipy 1.1.0\r\n",
      "    Uninstalling scipy-1.1.0:\r\n",
      "      Successfully uninstalled scipy-1.1.0\r\n",
      "  Found existing installation: scikit-learn 0.20.3\r\n",
      "    Uninstalling scikit-learn-0.20.3:\r\n",
      "      Successfully uninstalled scikit-learn-0.20.3\r\n",
      "  Found existing installation: python-dateutil 2.6.0\r\n",
      "    Uninstalling python-dateutil-2.6.0:\r\n",
      "      Successfully uninstalled python-dateutil-2.6.0\r\n",
      "  Found existing installation: pandas 0.23.4\r\n",
      "    Uninstalling pandas-0.23.4:\r\n",
      "      Successfully uninstalled pandas-0.23.4\r\n",
      "  Found existing installation: psutil 5.6.1\r\n",
      "    Uninstalling psutil-5.6.1:\r\n",
      "      Successfully uninstalled psutil-5.6.1\r\n",
      "  Found existing installation: pytest-cov 2.6.1\r\n",
      "    Uninstalling pytest-cov-2.6.1:\r\n",
      "      Successfully uninstalled pytest-cov-2.6.1\r\n",
      "  Found existing installation: future 0.17.1\r\n",
      "    Uninstalling future-0.17.1:\r\n",
      "      Successfully uninstalled future-0.17.1\r\n",
      "Successfully installed apipkg-1.5 atomicwrites-1.3.0 execnet-1.5.0 future-0.16.0 h2o4gpu-0.3.1.10000 numpy-1.16.1 pandas-0.24.1 pluggy-0.9.0 psutil-5.4.5 pytest-3.10.1 pytest-cov-2.5.1 pytest-forked-0.2 pytest-xdist-1.22.2 python-dateutil-2.7.2 scikit-learn-0.20.2 scipy-1.2.1\r\n"
     ]
    }
   ],
   "source": [
    "!apt-get install -y libopenblas-dev pbzip2\n",
    "!pip install -U tabulate==0.8.2\n",
    "!pip install h2o4gpu\n",
    "import h2o4gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and process netflix dataset to scipy sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing ../input/combined_data_1.txt\n",
      "processing ../input/combined_data_2.txt\n",
      "processing ../input/combined_data_3.txt\n",
      "processing ../input/combined_data_4.txt\n",
      "transformation...\n",
      "R matrix size (480189, 17770)\n",
      "splitting into training and validation set\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "files = [\n",
    "    '../input/combined_data_1.txt',\n",
    "    '../input/combined_data_2.txt',\n",
    "    '../input/combined_data_3.txt',\n",
    "    '../input/combined_data_4.txt',\n",
    "]\n",
    "\n",
    "coo_row = []\n",
    "coo_col = []\n",
    "coo_val = []\n",
    "\n",
    "for file_name in files:\n",
    "    print('processing {0}'.format(file_name))\n",
    "    with open(file_name, \"r\") as f:\n",
    "        movie = -1\n",
    "        for line in f:\n",
    "            if line.endswith(':\\n'):\n",
    "                movie = int(line[:-2]) - 1\n",
    "                continue\n",
    "            assert movie >= 0\n",
    "            splitted = line.split(',')\n",
    "            user = int(splitted[0])\n",
    "            rating = float(splitted[1])\n",
    "            coo_row.append(user)\n",
    "            coo_col.append(movie)\n",
    "            coo_val.append(rating)\n",
    "    gc.collect()\n",
    "\n",
    "print('transformation...')\n",
    "\n",
    "coo_val = np.array(coo_val, dtype=np.float32)\n",
    "coo_col = np.array(coo_col, dtype=np.int32)\n",
    "coo_row = np.array(coo_row)\n",
    "user, indices = np.unique(coo_row, return_inverse=True)\n",
    "user = user.astype(np.int32)\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "coo_matrix = scipy.sparse.coo_matrix((coo_val, (indices, coo_col)))\n",
    "shape = coo_matrix.shape\n",
    "print('R matrix size', shape)\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print('splitting into training and validation set')\n",
    "train_row, test_row, train_col, test_col, train_data, test_data = train_test_split(\n",
    "    coo_matrix.row, coo_matrix.col, coo_matrix.data, test_size=0.2, random_state=42)\n",
    "\n",
    "train = scipy.sparse.coo_matrix(\n",
    "    (train_data, (train_row, train_col)), shape=shape)\n",
    "test = scipy.sparse.coo_matrix(\n",
    "    (test_data, (test_row, test_col)), shape=shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's factorize matrix R "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 train: 0.8289686441421509 cv: 0.9866130352020264\n",
      "iteration 1 train: 0.7518881559371948 cv: 0.9291425347328186\n",
      "iteration 2 train: 0.721118152141571 cv: 0.9005951285362244\n",
      "iteration 3 train: 0.7065906524658203 cv: 0.8870471119880676\n",
      "iteration 4 train: 0.6984377503395081 cv: 0.8793769478797913\n",
      "iteration 5 train: 0.6933264136314392 cv: 0.8745821118354797\n",
      "iteration 6 train: 0.6898868680000305 cv: 0.871374785900116\n",
      "iteration 7 train: 0.6874406933784485 cv: 0.8690966963768005\n",
      "iteration 8 train: 0.6856245994567871 cv: 0.8673988580703735\n",
      "iteration 9 train: 0.6842295527458191 cv: 0.8660860657691956\n",
      "iteration 10 train: 0.6831294894218445 cv: 0.865032434463501\n",
      "iteration 11 train: 0.6822428107261658 cv: 0.8641777634620667\n",
      "iteration 12 train: 0.6815149188041687 cv: 0.8634673357009888\n",
      "iteration 13 train: 0.6809085011482239 cv: 0.8628664612770081\n",
      "iteration 14 train: 0.6803968548774719 cv: 0.8623507618904114\n",
      "iteration 15 train: 0.6799608469009399 cv: 0.8619084358215332\n",
      "iteration 16 train: 0.6795856952667236 cv: 0.8615224957466125\n",
      "iteration 17 train: 0.6792604923248291 cv: 0.8611842393875122\n",
      "iteration 18 train: 0.6789762377738953 cv: 0.8608867526054382\n",
      "iteration 19 train: 0.6787264347076416 cv: 0.8606215715408325\n",
      "iteration 20 train: 0.6785054206848145 cv: 0.8603858947753906\n",
      "iteration 21 train: 0.6783087253570557 cv: 0.8601757287979126\n",
      "iteration 22 train: 0.6781330704689026 cv: 0.8599879741668701\n",
      "iteration 23 train: 0.6779754757881165 cv: 0.8598180413246155\n",
      "iteration 24 train: 0.6778332591056824 cv: 0.8596658706665039\n",
      "iteration 25 train: 0.6777045726776123 cv: 0.8595287799835205\n",
      "iteration 26 train: 0.6775878071784973 cv: 0.8594040274620056\n",
      "iteration 27 train: 0.6774814128875732 cv: 0.8592907786369324\n",
      "iteration 28 train: 0.6773841977119446 cv: 0.8591877222061157\n",
      "iteration 29 train: 0.6772952675819397 cv: 0.8590916395187378\n",
      "iteration 30 train: 0.6772133708000183 cv: 0.859004020690918\n",
      "iteration 31 train: 0.6771381497383118 cv: 0.8589230179786682\n",
      "iteration 32 train: 0.6770687103271484 cv: 0.8588467240333557\n",
      "iteration 33 train: 0.6770044565200806 cv: 0.8587760925292969\n",
      "iteration 34 train: 0.67694491147995 cv: 0.8587103486061096\n",
      "iteration 35 train: 0.6768897771835327 cv: 0.8586480021476746\n",
      "iteration 36 train: 0.6768384575843811 cv: 0.8585891723632812\n",
      "iteration 37 train: 0.6767905950546265 cv: 0.8585346937179565\n",
      "iteration 38 train: 0.6767460107803345 cv: 0.8584830164909363\n",
      "iteration 39 train: 0.6767044067382812 cv: 0.8584336638450623\n",
      "iteration 40 train: 0.6766654849052429 cv: 0.8583874106407166\n",
      "iteration 41 train: 0.6766290068626404 cv: 0.8583438992500305\n",
      "iteration 42 train: 0.6765947341918945 cv: 0.8583023548126221\n",
      "iteration 43 train: 0.6765626668930054 cv: 0.8582625985145569\n",
      "iteration 44 train: 0.6765324473381042 cv: 0.8582264184951782\n",
      "iteration 45 train: 0.6765040159225464 cv: 0.8581914305686951\n",
      "iteration 46 train: 0.6764771938323975 cv: 0.8581581711769104\n",
      "iteration 47 train: 0.6764519810676575 cv: 0.8581268191337585\n",
      "iteration 48 train: 0.6764281392097473 cv: 0.8580968976020813\n",
      "iteration 49 train: 0.676405668258667 cv: 0.8580691814422607\n",
      "iteration 50 train: 0.6763843297958374 cv: 0.8580424785614014\n",
      "iteration 51 train: 0.6763642430305481 cv: 0.8580175042152405\n",
      "iteration 52 train: 0.6763450503349304 cv: 0.857994019985199\n",
      "iteration 53 train: 0.6763269901275635 cv: 0.8579714894294739\n",
      "iteration 54 train: 0.6763097643852234 cv: 0.8579504489898682\n",
      "iteration 55 train: 0.6762934327125549 cv: 0.8579297661781311\n",
      "iteration 56 train: 0.6762779355049133 cv: 0.8579106330871582\n",
      "iteration 57 train: 0.6762632131576538 cv: 0.8578919172286987\n",
      "iteration 58 train: 0.6762492060661316 cv: 0.8578746318817139\n",
      "iteration 59 train: 0.6762357950210571 cv: 0.8578572869300842\n",
      "iteration 60 train: 0.6762230396270752 cv: 0.8578416705131531\n",
      "iteration 61 train: 0.6762107610702515 cv: 0.8578258156776428\n",
      "iteration 62 train: 0.676199197769165 cv: 0.8578113317489624\n",
      "iteration 63 train: 0.6761881709098816 cv: 0.8577970862388611\n",
      "iteration 64 train: 0.6761775612831116 cv: 0.8577834963798523\n",
      "iteration 65 train: 0.6761674284934998 cv: 0.8577712774276733\n",
      "iteration 66 train: 0.6761576533317566 cv: 0.8577579259872437\n",
      "iteration 67 train: 0.6761483550071716 cv: 0.8577456474304199\n",
      "iteration 68 train: 0.6761394739151001 cv: 0.857733964920044\n",
      "iteration 69 train: 0.6761309504508972 cv: 0.8577221035957336\n",
      "iteration 70 train: 0.676122784614563 cv: 0.8577110767364502\n",
      "iteration 71 train: 0.6761148571968079 cv: 0.8577004075050354\n",
      "iteration 72 train: 0.6761074066162109 cv: 0.8576898574829102\n",
      "iteration 73 train: 0.6761000752449036 cv: 0.8576800227165222\n",
      "iteration 74 train: 0.6760930418968201 cv: 0.8576709032058716\n",
      "iteration 75 train: 0.67608642578125 cv: 0.8576615452766418\n",
      "iteration 76 train: 0.6760799884796143 cv: 0.8576527237892151\n",
      "iteration 77 train: 0.6760737299919128 cv: 0.8576439023017883\n",
      "iteration 78 train: 0.6760677695274353 cv: 0.857635498046875\n",
      "iteration 79 train: 0.6760619282722473 cv: 0.8576272130012512\n",
      "iteration 80 train: 0.6760563850402832 cv: 0.8576191663742065\n",
      "iteration 81 train: 0.676051139831543 cv: 0.8576115369796753\n",
      "iteration 82 train: 0.676045835018158 cv: 0.8576041460037231\n",
      "iteration 83 train: 0.6760408282279968 cv: 0.8575975298881531\n",
      "iteration 84 train: 0.67603600025177 cv: 0.8575907945632935\n",
      "iteration 85 train: 0.6760312914848328 cv: 0.8575837016105652\n",
      "iteration 86 train: 0.6760266423225403 cv: 0.8575775623321533\n",
      "iteration 87 train: 0.6760223507881165 cv: 0.8575709462165833\n",
      "iteration 88 train: 0.6760179996490479 cv: 0.8575648069381714\n",
      "iteration 89 train: 0.6760138869285583 cv: 0.8575589060783386\n",
      "iteration 90 train: 0.6760098934173584 cv: 0.8575544357299805\n",
      "iteration 91 train: 0.6760059595108032 cv: 0.8575488328933716\n",
      "iteration 92 train: 0.6760022044181824 cv: 0.8575432896614075\n",
      "iteration 93 train: 0.6759984493255615 cv: 0.8575379848480225\n",
      "iteration 94 train: 0.6759949326515198 cv: 0.8575326800346375\n",
      "iteration 95 train: 0.6759915351867676 cv: 0.8575276732444763\n",
      "iteration 96 train: 0.6759880781173706 cv: 0.8575232028961182\n",
      "iteration 97 train: 0.6759847402572632 cv: 0.857519268989563\n",
      "iteration 98 train: 0.6759815216064453 cv: 0.8575149178504944\n",
      "iteration 99 train: 0.675978422164917 cv: 0.8575111031532288\n",
      "best iteration: 99\n"
     ]
    }
   ],
   "source": [
    "n_components = 40\n",
    "_lambda = 0.01\n",
    "# increase it in case out-of GPU memory, but n_components / BATCHES has to be a multiple of 10\n",
    "BATCHES=1\n",
    "\n",
    "\n",
    "\n",
    "scores = []\n",
    "factorization = h2o4gpu.solvers.FactorizationH2O(\n",
    "    n_components, _lambda, max_iter=100)\n",
    "factorization.fit(train, X_test=test, X_BATCHES=BATCHES,\n",
    "                      THETA_BATCHES=BATCHES, scores=scores, verbose=True, early_stopping_rounds=5)\n",
    "print('best iteration:',factorization.best_iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now `factorization.XT` and `factorization.thetaT` contain dense representation of users and movies respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (480189, 40)\n",
      "ThetaT shape: (17770, 40)\n"
     ]
    }
   ],
   "source": [
    "print('X shape:', factorization.XT.shape)\n",
    "print('ThetaT shape:', factorization.thetaT.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
